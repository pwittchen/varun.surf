# general config
server.port=8080
spring.application.name=varun.surf

# parameter below refers to REST API config
spring.threads.virtual.enabled=false

# AI/LLM config
app.feature.ai.forecast.analysis.enabled=false
# available providers: ollama, openai
app.ai.provider=ollama

spring.ai.openai.api-key=YOUR_API_KEY
spring.ai.openai.chat.options.model=gpt-4o-mini

spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=smollm2:135m